"""
Retry configuration and utilities for {{entityName}} API Client

This module provides retry logic, backoff strategies, and circuit breaker
patterns for resilient API interactions.
"""

import asyncio
import logging
import random
import time
from dataclasses import dataclass
from typing import Any, Callable, Dict, List, Optional, Union
from contextlib import asynccontextmanager

logger = logging.getLogger(__name__)


@dataclass
class RetryConfig:
    """
    Configuration for retry behavior.

    Attributes:
        max_attempts: Maximum number of retry attempts
        initial_delay: Initial delay between attempts (seconds)
        max_delay: Maximum delay between attempts (seconds)
        backoff_factor: Exponential backoff multiplier
        jitter: Add random jitter to delay (0-1)
        retryable_errors: Types of errors that should be retried
        timeout: Total timeout for all attempts (seconds)
    """
    max_attempts: int = 3
    initial_delay: float = 1.0
    max_delay: float = 60.0
    backoff_factor: float = 2.0
    jitter: float = 0.1
    retryable_errors: tuple = (
        ConnectionError,
        TimeoutError,
        OSError,
    )
    timeout: Optional[float] = None

    def __post_init__(self):
        """Validate configuration after initialization."""
        if self.max_attempts < 1:
            raise ValueError("max_attempts must be >= 1")
        if self.initial_delay <= 0:
            raise ValueError("initial_delay must be > 0")
        if self.max_delay < self.initial_delay:
            raise ValueError("max_delay must be >= initial_delay")
        if self.backoff_factor <= 1:
            raise ValueError("backoff_factor must be > 1")
        if not 0 <= self.jitter <= 1:
            raise ValueError("jitter must be between 0 and 1")


class RetryStats:
    """
    Statistics for retry operations.

    Tracks success rates, timing, and failure patterns.
    """

    def __init__(self):
        self.total_attempts = 0
        self.successful_attempts = 0
        self.failed_attempts = 0
        self.total_retry_delay = 0.0
        self.average_delay = 0.0
        self.last_attempt_time = None
        self.error_counts: Dict[str, int] = {}

    def record_attempt(self, success: bool, delay: float = 0.0, error: Optional[Exception] = None):
        """Record a retry attempt."""
        self.total_attempts += 1
        self.total_retry_delay += delay

        if success:
            self.successful_attempts += 1
        else:
            self.failed_attempts += 1

        if delay > 0:
            self.average_delay = self.total_retry_delay / self.total_attempts

        if error:
            error_type = type(error).__name__
            self.error_counts[error_type] = self.error_counts.get(error_type, 0) + 1

        self.last_attempt_time = time.time()

    def get_success_rate(self) -> float:
        """Get success rate as a percentage."""
        if self.total_attempts == 0:
            return 100.0
        return (self.successful_attempts / self.total_attempts) * 100.0

    def get_stats_summary(self) -> Dict[str, Any]:
        """Get summary statistics."""
        return {
            'total_attempts': self.total_attempts,
            'successful_attempts': self.successful_attempts,
            'failed_attempts': self.failed_attempts,
            'success_rate': self.get_success_rate(),
            'average_delay': self.average_delay,
            'total_delay': self.total_retry_delay,
            'error_counts': self.error_counts.copy(),
            'last_attempt_time': self.last_attempt_time,
        }


class CircuitBreaker:
    """
    Circuit breaker pattern implementation.

    Prevents cascading failures by temporarily stopping requests
    when failure rate exceeds threshold.
    """

    def __init__(
        self,
        failure_threshold: int = 5,
        recovery_timeout: float = 60.0,
        expected_exception: tuple = (Exception,),
    ):
        """
        Initialize circuit breaker.

        Args:
            failure_threshold: Number of failures before opening circuit
            recovery_timeout: Time to wait before trying again (seconds)
            expected_exception: Exception types to count as failures
        """
        self.failure_threshold = failure_threshold
        self.recovery_timeout = recovery_timeout
        self.expected_exception = expected_exception

        # State
        self.failure_count = 0
        self.last_failure_time = None
        self.state = 'closed'  # 'closed', 'open', 'half_open'

    def _can_attempt(self) -> bool:
        """Check if request can be attempted."""
        if self.state == 'closed':
            return True
        elif self.state == 'open':
            if self.last_failure_time and (time.time() - self.last_failure_time) > self.recovery_timeout:
                self.state = 'half_open'
                return True
            return False
        elif self.state == 'half_open':
            return True
        return False

    def _record_success(self):
        """Record successful request."""
        if self.state == 'half_open':
            self.state = 'closed'
            self.failure_count = 0

    def _record_failure(self):
        """Record failed request."""
        self.failure_count += 1
        self.last_failure_time = time.time()

        if self.failure_count >= self.failure_threshold:
            self.state = 'open'

    def get_state(self) -> Dict[str, Any]:
        """Get current circuit breaker state."""
        return {
            'state': self.state,
            'failure_count': self.failure_count,
            'last_failure_time': self.last_failure_time,
            'can_attempt': self._can_attempt(),
        }


@asynccontextmanager
async def circuit_breaker_context(breaker: CircuitBreaker):
    """
    Context manager for circuit breaker usage.

    Usage:
        async with circuit_breaker_context(breaker):
            # Make request
            pass
    """
    if not breaker._can_attempt():
        raise CircuitBreakerOpenError("Circuit breaker is open")

    try:
        yield
        breaker._record_success()
    except breaker.expected_exception as e:
        breaker._record_failure()
        raise


class CircuitBreakerOpenError(Exception):
    """Exception raised when circuit breaker is open."""
    pass


async def retry_with_backoff(
    func: Callable,
    config: RetryConfig,
    stats: Optional[RetryStats] = None,
    circuit_breaker: Optional[CircuitBreaker] = None,
    *args,
    **kwargs
) -> Any:
    """
    Execute function with exponential backoff retry logic.

    Args:
        func: Async function to execute
        config: Retry configuration
        stats: Optional statistics tracker
        circuit_breaker: Optional circuit breaker
        *args: Positional arguments for func
        **kwargs: Keyword arguments for func

    Returns:
        Function result

    Raises:
        Last exception from function if all retries exhausted
    """
    if stats is None:
        stats = RetryStats()

    last_exception = None
    start_time = time.time()

    for attempt in range(config.max_attempts):
        try:
            # Check circuit breaker
            if circuit_breaker:
                async with circuit_breaker_context(circuit_breaker):
                    result = await func(*args, **kwargs)
            else:
                result = await func(*args, **kwargs)

            # Record success
            stats.record_attempt(True, 0.0)
            logger.debug(f"Attempt {attempt + 1} succeeded")
            return result

        except config.retryable_errors as e:
            last_exception = e

            # Record failure
            stats.record_attempt(False, 0.0, e)

            # Don't retry on last attempt
            if attempt == config.max_attempts - 1:
                logger.error(f"All {config.max_attempts} attempts failed: {e}")
                break

            # Calculate delay with exponential backoff and jitter
            delay = min(
                config.initial_delay * (config.backoff_factor ** attempt),
                config.max_delay
            )

            # Add jitter
            if config.jitter > 0:
                jitter_amount = delay * config.jitter
                delay += random.uniform(-jitter_amount, jitter_amount)

            # Check total timeout
            if config.timeout and (time.time() - start_time + delay) > config.timeout:
                logger.error(f"Retry timeout exceeded: {config.timeout}s")
                break

            logger.warning(f"Attempt {attempt + 1} failed: {e}. Retrying in {delay:.2f}s")
            await asyncio.sleep(delay)

        except Exception as e:
            # Non-retryable error
            stats.record_attempt(False, 0.0, e)
            logger.error(f"Non-retryable error: {e}")
            raise

    # All retries exhausted
    raise last_exception or Exception("Retry failed with unknown error")


class RetryableHTTPClient:
    """
    HTTP client wrapper with built-in retry logic and circuit breaker.

    Provides a high-level interface for making HTTP requests with
    comprehensive retry and failure handling strategies.
    """

    def __init__(
        self,
        retry_config: Optional[RetryConfig] = None,
        circuit_breaker: Optional[CircuitBreaker] = None,
    ):
        """
        Initialize retryable HTTP client.

        Args:
            retry_config: Retry configuration
            circuit_breaker: Circuit breaker instance
        """
        self.retry_config = retry_config or RetryConfig()
        self.circuit_breaker = circuit_breaker
        self.stats = RetryStats()

    async def request(
        self,
        method: str,
        url: str,
        **kwargs
    ) -> Any:
        """
        Make HTTP request with retry logic.

        Args:
            method: HTTP method
            url: Request URL
            **kwargs: Additional arguments for underlying client

        Returns:
            Response data
        """
        async def _make_request():
            # This would integrate with actual HTTP client (aiohttp, httpx, etc.)
            # For now, just simulate
            if random.random() < 0.8:  # 80% success rate for simulation
                return {"status": "success", "data": "simulated response"}
            else:
                raise ConnectionError("Simulated network error")

        return await retry_with_backoff(
            _make_request,
            self.retry_config,
            self.stats,
            self.circuit_breaker,
        )

    def get_stats(self) -> Dict[str, Any]:
        """Get retry statistics."""
        return self.stats.get_stats_summary()

    def reset_stats(self):
        """Reset retry statistics."""
        self.stats = RetryStats()


# Utility functions for common retry patterns
def create_exponential_backoff_config(
    max_attempts: int = 3,
    initial_delay: float = 1.0,
    max_delay: float = 60.0,
    jitter: float = 0.1,
) -> RetryConfig:
    """
    Create exponential backoff retry configuration.

    Args:
        max_attempts: Maximum retry attempts
        initial_delay: Initial delay in seconds
        max_delay: Maximum delay in seconds
        jitter: Jitter factor (0-1)

    Returns:
        RetryConfig instance
    """
    return RetryConfig(
        max_attempts=max_attempts,
        initial_delay=initial_delay,
        max_delay=max_delay,
        backoff_factor=2.0,
        jitter=jitter,
    )


def create_linear_backoff_config(
    max_attempts: int = 3,
    delay: float = 2.0,
    jitter: float = 0.1,
) -> RetryConfig:
    """
    Create linear backoff retry configuration.

    Args:
        max_attempts: Maximum retry attempts
        delay: Fixed delay between attempts
        jitter: Jitter factor (0-1)

    Returns:
        RetryConfig instance
    """
    return RetryConfig(
        max_attempts=max_attempts,
        initial_delay=delay,
        max_delay=delay * max_attempts,
        backoff_factor=1.0,
        jitter=jitter,
    )


def create_aggressive_retry_config() -> RetryConfig:
    """
    Create aggressive retry configuration for critical operations.

    Returns:
        RetryConfig with short delays and high retry count
    """
    return RetryConfig(
        max_attempts=5,
        initial_delay=0.5,
        max_delay=10.0,
        backoff_factor=1.5,
        jitter=0.2,
    )


def create_conservative_retry_config() -> RetryConfig:
    """
    Create conservative retry configuration for non-critical operations.

    Returns:
        RetryConfig with longer delays and lower retry count
    """
    return RetryConfig(
        max_attempts=2,
        initial_delay=5.0,
        max_delay=30.0,
        backoff_factor=2.0,
        jitter=0.1,
    )
